{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4zelglxaZxK"
      },
      "source": [
        "Taller De Credit Fraud Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7c0SK6tUaZxM"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import HTML\n",
        "\n",
        "# sys.path.append(\"code/.\")\n",
        "\n",
        "#import mglearn\n",
        "from IPython.display import display\n",
        "#from plotting_functions import *\n",
        "\n",
        "\n",
        "# Preprocessing and pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from scipy.stats import reciprocal\n",
        "\n",
        "# train test split and cross validation\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge, Lasso, LogisticRegression\n",
        "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import (\n",
        "    MinMaxScaler,\n",
        "    OneHotEncoder,\n",
        "    OrdinalEncoder,\n",
        "    StandardScaler,\n",
        "    PolynomialFeatures,\n",
        ")\n",
        "# pd.set_option(\"display.max_colwidth\", 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxzv-cRoaZxO",
        "outputId": "9cddc17e-3782-43dc-9aa3-96a7369020b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of transactions: 568630\n",
            "Number of fraudulent transactions: 284315\n",
            "Number of good transactions: 284315\n",
            "Total number of transactions after drop: 552035\n",
            "Number of fraudulent transactions after drop: 276845\n",
            "Number of good transactions after drop: 275190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-af9378bb9fbd>:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr.drop_duplicates(subset=columns_to_consider, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "#Cargamos los datos y procesamos algunas columnas\n",
        "df = pd.read_csv('creditcard_2023.csv')\n",
        "\n",
        "#Dado el tamangio del data set se deben eliminar unas columnas y filas repetidas para agilizar el modelamiento\n",
        "# Calculate the correlation matrix for numerical columns\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Get the correlation of each feature with the \"Class\" column\n",
        "correlation_with_class = correlation_matrix[\"Class\"].sort_values(ascending=False)\n",
        "\n",
        "# Plot a heatmap of the correlation matrix\n",
        "# plt.figure(figsize=(12, 8))\n",
        "# sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=False)\n",
        "# plt.title(\"Correlation Matrix Heatmap\")\n",
        "# plt.show()\n",
        "# Print the correlations with the \"Class\" column\n",
        "#print(\"Correlation with Class:\\n\", correlation_with_class)\n",
        "\n",
        "# Drop any rows that are completely duplicated\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Print the total number of transactions\n",
        "print(\"Total number of transactions:\", df.shape[0])\n",
        "# Print the number of fraudulent transactions\n",
        "print(\"Number of fraudulent transactions:\", df[df['Class'] == 1].shape[0])\n",
        "# Print the number of good transactions\n",
        "print(\"Number of good transactions:\", df[df['Class'] == 0].shape[0])\n",
        "\n",
        "# Selecting columns where absolute correlation with 'Class' is higher than 0.4\n",
        "relevant_features = correlation_with_class[correlation_with_class.abs() > 0.4].index\n",
        "# Dataframe with only relevant features\n",
        "df_corr = df[relevant_features]\n",
        "\n",
        "df_corr.to_csv('filtered_creditcard_2023.csv', index=False)\n",
        "# print(df.head())\n",
        "\n",
        "columns_to_consider = [col for col in df_corr.columns if col not in ['id', 'Amount', 'Class']]\n",
        "\n",
        "# Drop duplicates, considering only the columns in 'columns_to_consider'\n",
        "df_corr.drop_duplicates(subset=columns_to_consider, inplace=True)\n",
        "\n",
        "# Print the total number of transactions\n",
        "print(\"Total number of transactions after drop:\", df_corr.shape[0])\n",
        "# Print the number of fraudulent transactions\n",
        "print(\"Number of fraudulent transactions after drop:\", df_corr[df_corr['Class'] == 1].shape[0])\n",
        "# Print the number of good transactions\n",
        "print(\"Number of good transactions after drop:\", df_corr[df_corr['Class'] == 0].shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Oi2Zr0XWaZxP"
      },
      "outputs": [],
      "source": [
        "#Separar los datos en entrenamiento, validación y test\n",
        "train_df, test_df = train_test_split(df_corr, test_size=0.2, random_state=1)\n",
        "\n",
        "#Definir características y variable objetivo\n",
        "X_train = train_df.drop(columns=[\"Class\"])\n",
        "y_train = train_df[\"Class\"]\n",
        "\n",
        "X_test = test_df.drop(columns=[\"Class\"])\n",
        "y_test = test_df[\"Class\"]\n",
        "\n",
        "# #Índices de las columnas numéricas y categ+oricas\n",
        "# cat_cols = X_train.select_dtypes(include=object).columns\n",
        "# num_cols = X_train.select_dtypes(include=np.number).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TQRLFKbWaZxQ"
      },
      "outputs": [],
      "source": [
        "#Se seleccionan todas las columnas\n",
        "num_cols = X_train.select_dtypes(include=np.number).columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRqJYcDyaZxQ",
        "outputId": "16f12502-48f3-48fe-bda2-5d8d10539a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV(estimator=Pipeline(steps=[('classifier', LogisticRegression())]),\n",
            "             n_jobs=-1,\n",
            "             param_grid={'classifier__C': array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
            "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
            "       2.15443469e+02, 1.00000000e+03]),\n",
            "                         'classifier__solver': ['lbfgs', 'saga']},\n",
            "             scoring='accuracy')\n",
            "{'classifier__C': 0.1, 'classifier__solver': 'lbfgs'}\n",
            "Modelo regresión logística\n",
            "Accuracy: 0.993605477913538\n"
          ]
        }
      ],
      "source": [
        "#Definimos el clasificador base\n",
        "logreg_base = LogisticRegression()\n",
        "clf_logreg = Pipeline(steps=[(\"classifier\", logreg_base)])\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__solver': ['lbfgs', 'saga'],\n",
        "    'classifier__C': np.logspace(-3, 3, 10),\n",
        "    'classifier__penalty': ['l2'],  # maybe just one type of penalty\n",
        "}\n",
        "\n",
        "search_logreg = GridSearchCV(clf_logreg, param_grid, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "search_logreg.fit(X_train, y_train)\n",
        "print(search_logreg)\n",
        "print(search_logreg.best_params_)\n",
        "\n",
        "# Obtengamos el accuracy para la regresión logística\n",
        "print('Modelo regresión logística')\n",
        "print(f'Accuracy: {search_logreg.score(X_test, y_test)}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}